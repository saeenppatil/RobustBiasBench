{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16, # make it float32 if you face errors or ping me\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"./offload\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "df = pd.read_csv(\"FINAL_PERTURBED_DATASET.csv\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsOFY-W0VxdO"
   },
   "source": [
    "**NO SHOT PERTURBED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perturbed 0 shot\n",
    "import re\n",
    "tqdm.pandas()\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "def classify_bias(policy):\n",
    "    prompt = [\n",
    "          {\"role\": \"system\",\n",
    "         \"content\": (f\"You are a policy-analysis assistant.\\n\"\n",
    "                     f\"Given a policy excerpt, output *exactly one* of these three labels—nothing else, all lower-case:\\n\"\n",
    "                     f\"- no_bias\\n\"\n",
    "                     f\"- group_1 (political, criminal_justice, citizenship, disability, education)\\n\"\n",
    "                     f\"- group_2 \\n\\n\"\n",
    "                     f\"Definitions:\\n\"\n",
    "                     f\"- *group_2*: policies related to identity, social, and economic status, including:\\n\"\n",
    "                     f\"• economic: references income, poverty, homelessness, wealth, financial assistance, costs, payments, fees, funding, housing, area living in, etc.\\n\"\n",
    "                     f\"• racial_cultural: references race, ethnicity, culture, personal beliefs, etc.\\n\"\n",
    "                     f\"• age: references children, youth, child welfare policies, adults, elderly, seniors, age-related policies, etc.\\n\"\n",
    "                     f\"• religion: references religious beliefs, religious groups, faith-based accommodations, etc.\\n\"\n",
    "                     f\"• gender: references women, men, sex, gender identity, use of only one pronoun for a role, sexual harassment, reproductive rights, pregnancy, etc.\\n\\n\"\n",
    "                     f\"- *group_1*: policies related to legal, institutional, or civic systems, including:\\n\"\n",
    "                     f\"• political: references voting rights, politics, elections, campaigns, government, war, international relations etc.1\\n\"\n",
    "                     f\"• criminal_justice: references crime, criminals, court, law enforcement, policing, prison, etc.\\n\"\n",
    "                     f\"• citizenship: references immigration, immigration status, deportation, visas, border control, etc.\\n\"\n",
    "                     f\"• disability: references physical or mental impairments, accommodations for impairments, accessibility, illness, etc.\\n\"\n",
    "                     f\"• education: curriculum, degrees, teaching credentials, language proficiency, language required to learn, standardized testing, school admission, etc.\\n\"\n",
    "                     f\"- *no_bias*: procedural, definitional, administrative, factual, or operational text, like implementation details or definitions.\\n\\n\" #highlighted no_bias\n",
    "                     f\"Decision Rules:\\n\"\n",
    "                     f\"- Focus on legal or civic status -> group_1.\\n\"\n",
    "                     f\"- Focus on economic standing or demographic identity -> group_2.\\n\"\n",
    "                     f\"- Purely procedural/factual -> no_bias.\\n\"\n",
    "                     )},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": (f\"Classify the following excerpt:\\n\"\n",
    "                     f\"\\\"\\\"\\\"\\n\"\n",
    "                     f\"{policy}\\n\"\n",
    "                     f\"\\\"\\\"\\\"\"\n",
    "                     f\"When uncertain, pick the best matching category. No explanations.\\n\"\n",
    "                     f\"Return *only* one of: group_1, group_2, no_bias,\\n\\n\"\n",
    "\n",
    "                )}\n",
    "              ]\n",
    "\n",
    "\n",
    "    result = pipe(prompt, max_new_tokens=10, do_sample=False)\n",
    "    generated_text = result[0]['generated_text']\n",
    "    predicted = generated_text[-1][\"content\"].strip().split(\"\\n\")[0]\n",
    "    return predicted\n",
    "\n",
    "#################################################################################################\n",
    "# Define valid classes\n",
    "valid_labels = [\"group_2\", \"group_1\", \"no_bias\"]\n",
    "\n",
    "\n",
    "# Apply classifier\n",
    "df['predicted_bias'] = df['policy_perturbed'].progress_apply(classify_bias) #POLICY_PERTURBED\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#clean predictions\n",
    "df['predicted_bias'] = df['predicted_bias'].astype(str).str.strip().str.lower()\n",
    "df['bias_type_merged'] = df['bias_type_merged'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Accuracy\n",
    "df['correct'] = df['bias_type_merged'] == df['predicted_bias']\n",
    "accuracy = df['correct'].mean()\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Precision, Recall, F1\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    df['bias_type_merged'],\n",
    "    df['predicted_bias'],\n",
    "    labels=valid_labels,\n",
    "    digits=3\n",
    "))\n",
    "\n",
    "# download\n",
    "df.to_csv(\"Deepseek7B_Zero_Shot_Perturbed.csv\", index=False)\n",
    "\n",
    "# If in Colab or Jupyter:\n",
    "from google.colab import files\n",
    "files.download(\"Deepseek7B_Zero_Shot_Perturbed.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
