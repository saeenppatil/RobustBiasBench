# -*- coding: utf-8 -*-
"""qwen_inference_fewshot_perturbed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q1-sBuOYWDm0qa49h_7WkGHwxJQmdlme
"""

import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from tqdm import tqdm
import os
import time
from tqdm.notebook import tqdm
from datetime import timedelta
from google.colab import drive

# Set up progress bar for pandas
tqdm.pandas()

# Mount Google Drive first (only needs to be run once per session)
drive.mount('/content/drive')

# Define a path on your Google Drive to save results
DRIVE_PATH = "/content/drive/MyDrive/bias_classification_results"  # Change this to your desired folder
os.makedirs(DRIVE_PATH, exist_ok=True)  # Create the directory if it doesn't exist
output_path = f"{DRIVE_PATH}/bias_classification_perturbed_9shot_results.csv"

# Install required packages
!pip install -q transformers accelerate pandas tqdm huggingface_hub

# Login to Hugging Face
from huggingface_hub import login
login(token="REMOVED_SECRETtamLssrXWMvQGDXEsALoujghfRdYRsoOlq")

# Define model and device
model_name = "Qwen/Qwen2.5-7B-Instruct"
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# Load tokenizer and model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if device == "cuda" else torch.float32,
    device_map="auto"
)

# Create pipeline
pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)

# Load dataset
df = pd.read_csv("FINAL_PERTURBED_DATASET.csv")
bias_classes = ["no_bias", "group_1", "group_2"]

def classify_bias(description):
    system_prompt = (
        "You are a specialized policy-analysis assistant.\n\n"
        "Definitions:\n"
        "- A bias policy targets, benefits, burdens, limits, or distinguishes a population based on identity, legal status, or economic position.\n"
        "- A non-bias policy is entirely procedural, factual, or operational, and does not involve any group-based treatment\n\n"
        "Categories:\n"
        "GROUP_2 → IDENTITY OR SOCIOECONOMIC POLICIES - This is a PRIORITY category that may be subtle or implied:\n"
        "- economic: ANY mention of money, finances, income, poverty, wealth, financial assistance, housing, or benefits based on economic standing. This includes ANY housing policies (affordability, assistance programs, rent control, homelessness, property rights), ANY employment policies (wages, job training, unemployment, worker protections), ANY financial policies (loans, tax credits, subsidies, benefits based on income), or ANY policy that affects people differently based on their financial situation.\n"
        "- racial/cultural: ANY reference to race, ethnicity, cultural heritage, minorities, diversity, or related terminology. This includes ANY policy mentioning ethnic groups, cultural practices, racial identity, integration, diversity programs, affirmative action, racial disparities, language access based on cultural background, or indigenous communities.\n"
        "- age: ANY mention of age groups, elderly individuals, youth, children, seniors, or life stages. This includes ANY policy related to retirement, school-age children, youth programs, child welfare, elder care, senior benefits, age restrictions, or generational considerations. Even INDIRECT references to age-specific needs count here.\n"
        "- religion: ANY reference to faith, religious groups, spiritual practices, or religious accommodations. This includes ANY policy mentioning places of worship, religious holidays, religious exemptions, faith-based organizations, religious education, or any regulation that considers religious identity or practice.\n"
        "- gender: ANY mention of gender, sex, women, men, gender identity, sexual orientation, or gender-based rights. This includes ANY policy addressing sexual harassment, gender equality, reproductive rights, maternity/paternity policies, gender discrimination, LGBTQ+ protections, or gender-specific programs. Policies affecting women, men, or gender minorities ALL belong here.\n\n"
        "group_1 → Policies related to civic, institutional, or legal systems. Includes:\n"
        "- political: voting rights, elections, campaigns, or representation. This includes electoral processes, political participation, districting, governmental structures, or international relations.\n"
        "- criminal justice: law enforcement, courts, sentencing, prison, or rehabilitation. This includes policing policies, judicial proceedings, corrections, parole systems, or any aspect of the legal enforcement system.\n"
        "- citizenship: immigration status, visas, deportation, or naturalization. This includes border policies, citizenship requirements, asylum procedures, or voting rights related to citizenship status.\n"
        "- disability: accommodations or treatment for physical, mental, or learning impairments. This includes physical health accommodations, mental health services, accessibility requirements, or any policy that addresses different ability statuses.\n"
        "- education: curriculum, school placement, learning standards, language proficiency, or educational access. This includes academic policies, language requirements in schools, educational testing, teacher credentials, or school enrollment procedures.\n\n"
        "no_bias → Procedural, administrative, or operational text. Includes:\n"
        "- Scheduling, meeting logistics, budgeting language, implementation details, or general operations with no reference to any group.\n"
        "- Technical definitions, purely factual information, or administrative processes that apply universally.\n\n"
        "Guidelines:\n"
        "- IMPORTANT: If there is ANY hint or implication that a policy might affect people based on their identity or economic status, classify it as group_2. Even SUBTLE references count!\n"
        "- GROUP_2 is often under-identified - be vigilant for mentions of financial status, demographic characteristics, or identity-based distinctions.\n"
        "- If the policy mentions ANYTHING about how people are treated based on WHO THEY ARE (identity or economic status) → group_2.\n"
        "- Only if you're certain it's NOT about identity or economic factors, then consider if it focuses on legal rights, school policies, enforcement, or institutional rules → group_1.\n"
        "- Only classify as no_bias if you're absolutely certain the policy is purely administrative with NO implications for any identifiable group.\n"
        "- Output only the label: no_bias, group_1, or group_2."
    )

    user_prompt = (
        f"Classify the following policy excerpt.\n\n"
        f"Here are some examples of correct classifications:\n\n"
        f"Example 1\n"
        f"Policy: The job application process mandates that candidates disclose their age and retirement plans, with younger applicants prioritized for advancement.\n"
        f"Classification: group_2\n\n"
        f"Example 2\n"
        f"Policy: Tax exemptions will be granted to corporations investing over $5 million in designated opportunity zones.\n"
        f"Classification: group_2\n\n"
        f"Example 3\n"
        f"Policy: The bill excludes same‑sex partners from family leave benefits.\n"
        f"Classification: group_2\n\n"
        f"Example 4\n"
        f"Policy: Immigrants must demonstrate fluency in English and pass a civic exam to be eligible for naturalization.\n"
        f"Classification: group_1\n\n"
        f"Example 5\n"
        f"Policy: The policy mandates separate healthcare facilities for individuals with disabilities, citing operational constraints.\n"
        f"Classification: group_1\n\n"
        f"Example 6\n"
        f"Policy: A bill mandates non‑citizens charged with a Class 4 felony shall be designated deportable immediately upon indictment.\n"
        f"Classification: group_1\n\n"
        f"Example 7\n"
        f"Policy: The committee will meet quarterly to review environmental compliance reports.\n"
        f"Classification: no_bias\n\n"
        f"Example 8\n"
        f"Policy: Applicants must submit identity verification and a signed consent form for record access.\n"
        f"Classification: no_bias\n\n"
        f"Example 9\n"
        f"Policy: The funding request was approved following standard procurement guidelines and budgetary review.\n"
        f"Classification: no_bias\n\n"
        f"Now, classify the following excerpt:\n"
        f"Excerpt:\n\"\"\"\n{description}\n\"\"\"\n\n"
        f"Follow these exact steps in order:\n"
        f"Step 1: Does this policy mention OR IMPLY anything about ANY of these themes:\n"
        f"- Money, finances, income, poverty, wealth, housing, economic opportunity\n"
        f"- Race, ethnicity, cultural background, minority groups, diversity\n"
        f"- Age (elderly, children, youth, seniors, generational issues)\n"
        f"- Religion, faith, religious practices or accommodations\n"
        f"- Gender, sex, women's issues, men's issues, LGBTQ+ considerations\n"
        f"→ If the policy touches on ANY of these themes EVEN INDIRECTLY, choose group_2\n\n"
        f"Step 2: Only if you're certain it's NOT group_2, check if it involves:\n"
        f"- Education (schools, students, teachers, curriculum)\n"
        f"- Political matters (voting, elections, government functions)\n"
        f"- Criminal justice (law enforcement, courts, incarceration)\n"
        f"- Citizenship (immigration, visas, naturalization)\n"
        f"- Disability services (accommodations, accessibility)\n"
        f"→ If it involves any of these and NOT group_2 themes, choose group_1\n\n"
        f"Step 3: Only if the policy is purely procedural with NO group implications, choose no_bias\n\n"
        f"BE CAREFUL NOT TO MISS GROUP_2 POLICIES! Even subtle references to economic status or identity count as group_2.\n\n"
        f"Classification (return ONLY 'no_bias', 'group_1', or 'group_2'):"
    )

    # Apply the Qwen2.5 chat template
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    prompt = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )

    # Generate response
    outputs = pipe(prompt, max_new_tokens=10, do_sample=False)
    generated = outputs[0]['generated_text']
    raw_output = generated[len(prompt):].strip()
    prediction = raw_output.split("\n")[0].lower()

    # Extract the actual bias classification
    found_class = "unknown"
    for cls in bias_classes:
        if cls in prediction:
            found_class = cls
            break

    return found_class, raw_output

# Create a mapping from specific categories to their group labels
category_to_group = {
    # group_1 categories
    "political": "group_1",
    "criminal_justice": "group_1",
    "citizenship": "group_1",
    "disability": "group_1",
    "education": "group_1",

    # group_2 categories
    "economic": "group_2",
    "racial_cultural": "group_2",
    "age": "group_2",
    "religion": "group_2",
    "gender": "group_2",

    # no_bias remains the same
    "no_bias": "no_bias"
}

# Create a function to save results
def save_batch(batch_df, output_path=output_path):
    # Check if file exists to determine if we need headers
    header = not os.path.exists(output_path)
    batch_df.to_csv(output_path, mode='a', header=header, index=False)
    print(f"✓ Saved {len(batch_df)} rows to Drive")

# Define batch size and calculate batches
batch_size = 32
total_rows = len(df)
total_batches = (total_rows + batch_size - 1) // batch_size
print(f"Processing {total_rows} rows in {total_batches} batches")

# Check if we have previous results to resume from
if os.path.exists(output_path):
    existing_results = pd.read_csv(output_path)

    # Check if the CSV has the expected columns
    expected_columns = ['policy', 'bias_type', 'predicted_bias', 'raw_output', 'bias_type_group', 'correct']
    if all(col in existing_results.columns for col in expected_columns):
        rows_already_processed = len(existing_results)
        start_batch = rows_already_processed // batch_size

        if start_batch > 0:
            print(f"Found existing results with {rows_already_processed} rows.")
            print(f"Last processed batch was {start_batch}")
            print(f"Resuming from batch {start_batch+1}/{total_batches}")
    else:
        print("Warning: Existing results file has unexpected format. Starting from beginning.")
        start_batch = 0
else:
    start_batch = 0
    print("No existing results found. Starting from the beginning.")

# Initialize timing
start_time = time.time()

# Initialize overall accuracy tracking
total_correct = 0
total_processed = 0

# If resuming, get the current overall statistics
if start_batch > 0 and os.path.exists(output_path):
    existing_results = pd.read_csv(output_path)
    if 'correct' in existing_results.columns:
        total_correct = existing_results['correct'].sum()
        total_processed = len(existing_results)
        initial_accuracy = (total_correct / total_processed) * 100
        print(f"Initial overall accuracy: {initial_accuracy:.2f}% ({total_processed} rows)")

# Create a tqdm progress bar for tracking batches
# Adjust total to only count remaining batches
remaining_batches = total_batches - start_batch
batch_progress = tqdm(total=remaining_batches, desc="Overall Progress")

# Process all batches, starting from where we left off
for batch_idx in range(start_batch, total_batches):
    batch_start = time.time()

    # Get current batch
    start_idx = batch_idx * batch_size
    end_idx = min(start_idx + batch_size, total_rows)
    batch_df = df.iloc[start_idx:end_idx].copy()

    # Show batch info
    print(f"\nBatch {batch_idx+1}/{total_batches} (rows {start_idx+1}-{end_idx})")

    # Show time estimates if not the first batch
    if batch_idx > start_batch:
        elapsed = time.time() - start_time
        avg_time_per_batch = elapsed / (batch_idx - start_batch)
        remaining = avg_time_per_batch * (total_batches - batch_idx)

        # Display time info
        print(f"Elapsed: {str(timedelta(seconds=int(elapsed)))}")
        print(f"Remaining: {str(timedelta(seconds=int(remaining)))}")
        print(f"Est. completion: {time.strftime('%H:%M:%S', time.localtime(start_time + elapsed + remaining))}")

    # Process batch
    results = []
    for idx, row in enumerate(batch_df.itertuples()):
        result = classify_bias(row.policy_perturbed)
        results.append(result)

    batch_df['predicted_bias'] = [r[0] for r in results]
    batch_df['raw_output'] = [r[1] for r in results]

    # Map categories and calculate accuracy
    batch_df['bias_type_group'] = batch_df['bias_type'].str.strip().str.lower().map(category_to_group)
    batch_df['correct'] = batch_df['bias_type_group'] == batch_df['predicted_bias']
    batch_accuracy = batch_df['correct'].mean() * 100

    # Update overall statistics
    batch_correct = batch_df['correct'].sum()
    batch_size_actual = len(batch_df)
    total_correct += batch_correct
    total_processed += batch_size_actual
    overall_accuracy = (total_correct / total_processed) * 100

    # Save to Drive
    save_batch(batch_df)

    # Print accuracy information
    print(f"Batch accuracy: {batch_accuracy:.2f}% | Overall accuracy: {overall_accuracy:.2f}% ({total_processed} rows)")

    # Update batch progress bar
    batch_progress.update(1)
    batch_progress.set_postfix({
        "Batch Acc": f"{batch_accuracy:.1f}%",
        "Overall Acc": f"{overall_accuracy:.1f}%",
        "Rows": f"{end_idx}/{total_rows}"
    })

import pandas as pd
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Load the results dataset
df = pd.read_csv("bias_classification_perturbed_9shot_results.csv")

# Assuming the columns are named 'bias_type_group' for true labels and 'predicted_bias' for predictions
# If they have different names, adjust these variables
true_column = 'bias_type_group'  # Column containing true labels
pred_column = 'predicted_bias'   # Column containing model predictions

# Generate and print classification report
print("Classification Report:")
report = classification_report(df[true_column], df[pred_column])
print(report)

# Generate confusion matrix
conf_matrix = confusion_matrix(df[true_column], df[pred_column])
classes = sorted(df[true_column].unique())
conf_df = pd.DataFrame(conf_matrix, index=classes, columns=classes)
print("\nConfusion Matrix:")
print(conf_df)

# Calculate overall accuracy
accuracy = (df[true_column] == df[pred_column]).mean()
print(f"\nOverall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")

# Distribution of true labels and predictions
print("\nDistribution of True Labels:")
print(df[true_column].value_counts())

print("\nDistribution of Predicted Labels:")
print(df[pred_column].value_counts())