{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from huggingface_hub import login\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Log in to huggingface to use Mistral model\n",
    "login(\"\") # insert own token\n",
    "\n",
    "# Bias classes of dataset\n",
    "bias_classes = [\n",
    "    \"no_bias\", \"group_1\", \"group_2\"\n",
    "]\n",
    "\n",
    "# Load dataset with perturbed policy texts\n",
    "df = pd.read_csv(\"FINAL_PERTURBED_DATASET.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Mistral model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Mistral to predict the bias of a policy\n",
    "def classify_bias(description):\n",
    "    # Prompt for few-shot prediction with Mistral\n",
    "    prompt = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": (f\"You are a policy-analysis assistant.\\n\"\n",
    "                     f\"Given a policy excerpt, output *exactly one* of these three labels—nothing else, all lower-case:\\n\"\n",
    "                     f\"- group_2:\\n\"\n",
    "                     f\"- group_1:\\n\"\n",
    "                     f\"- no_bias\\n\\n\"\n",
    "                     f\"Definitions:\\n\"\n",
    "                     f\"- group_2: policies related to identity, social, and economic status, including:\\n\"\n",
    "                     f\"• economic: references income, poverty, homelessness, wealth, financial assistance, costs, payments, fees, funding, housing, area living in, etc.\\n\"\n",
    "                     f\"• racial_cultural: references race, ethnicity, culture, personal beliefs, etc.\\n\"\n",
    "                     f\"• age: references children, youth, child welfare policies, adults, elderly, seniors, age-related policies, etc.\\n\"\n",
    "                     f\"• religion: references religious beliefs, regligious groups, faith-based accommodations, etc.\\n\"\n",
    "                     f\"• gender: references women, men sex, gender identity, use of only one pronoun for a role, sexual harassment, reproductive rights, pregnancy, etc.\\n\"\n",
    "                     f\"- group_1: policies related to legal, institutional, or civic systems, including:\\n\"\n",
    "                     f\"• political: references voting rights, politics, elections, campaigns, government, war, international relations, etc.\\n\"\n",
    "                     f\"• criminal_justice: refernces crime, criminals, court, law enforcement, policing, prison, etc.\\n\"\n",
    "                     f\"• citizenship: references immigration, immigration status, deportation, visas, border control, etc.\\n\"\n",
    "                     f\"• disability: references physical or mental impairments, accommodations for impairments, accessibility, illness, etc.\\n\"\n",
    "                     f\"• education: curriculum, degrees, teaching credentials, language proficiency, language required to learn, standardized testing, school admission, etc.\\n\"\n",
    "                     f\"- no_bias: procedural, definitional, administrative, factual, or operational text, like implementation details or definitions.\\n\\n\"\n",
    "                     f\"Examples:\\n\"\n",
    "                     f\"Example 1\\n\"\n",
    "                     f\"Policy: The job application process mandates that candidates disclose their age and retirement plans, with younger applicants prioritized for advancement.\\n\"\n",
    "                     f\"Classification: group_2\\n\\n\"\n",
    "                     f\"Example 2\\n\"\n",
    "                     f\"Policy: Tax exemptions will be granted to corporations investing over $5 million in designated opportunity zones.\\n\"\n",
    "                     f\"Classification: group_2\\n\\n\"\n",
    "                     f\"Example 3\\n\"\n",
    "                     f\"Policy: The bill excludes same‑sex partners from family leave benefits.\\n\"\n",
    "                     f\"Classification: group_2\\n\\n\"\n",
    "                     f\"Example 4\\n\"\n",
    "                     f\"Policy: Immigrants must demonstrate fluency in English and pass a civic exam to be eligible for naturalization.\\n\"\n",
    "                     f\"Classification: group_1\\n\\n\"\n",
    "                     f\"Example 5\\n\"\n",
    "                     f\"Policy: The policy mandates separate healthcare facilities for individuals with disabilities, citing operational constraints.\\n\"\n",
    "                     f\"Classification: group_1\\n\\n\"\n",
    "                     f\"Example 6\\n\"\n",
    "                     f\"Policy: A bill mandates non‑citizens charged with a Class 4 felony shall be designated deportable immediately upon indictment.\\n\"\n",
    "                     f\"Classification: group_1\\n\\n\"\n",
    "                     f\"Example 7\\n\"\n",
    "                     f\"Policy: The committee will meet quarterly to review environmental compliance reports.\\n\"\n",
    "                     f\"Classification: no_bias\\n\\n\"\n",
    "                     f\"Example 8\\n\"\n",
    "                     f\"Policy: Applicants must submit identity verification and a signed consent form for record access.\\n\"\n",
    "                     f\"Classification: no_bias\\n\\n\"\n",
    "                     f\"Example 9\\n\"\n",
    "                     f\"Policy: The funding request was approved following standard procurement guidelines and budgetary review.\\n\"\n",
    "                     f\"Classification: no_bias\\n\\n\"\n",
    "                     f\"The order of the eaxmples do not matter. They have no significance in how you should classify excerpts.\\n\\n\"\n",
    "                     f\"Instructions:\\n\"\n",
    "                     f\"Follow the following steps exactly, when picking a label:\\n\"\n",
    "                     f\"Step 1: Does the excerpt fit under economic, racial_cultural, age, religion, or gender? If yes, pick group_2.\\n\"\n",
    "                     f\"Step 2: If the answer to Step 1 was \\\"no\\\", does the excerpt fit under political, criminal_justice, citizenship, disability, or education? If yes, pick group_1.\\n\"\n",
    "                     f\"Step 3: If the excerpt does not fit under group_1 or group_2, it is purely a procedure, a definition, or administrative, so pick no_bias.\\n\"\n",
    "                     f\"- Do not default to any label. All labels are equally possible for an excerpt.\\n\"\n",
    "                     f\"- Return just the label; no explanations.\"\n",
    "                     )},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": (f\"Classify the following policy excerpt.\\n\"\n",
    "                     f\"Return *only* one of: no_bias, group_1, group_2\\n\\n\"\n",
    "                     f\"Excerpt:\\n\"\n",
    "                     f\"\\\"\\\"\\\"\\n\"\n",
    "                     f\"{description}\\n\"\n",
    "                     f\"\\\"\\\"\\\"\"\n",
    "                     )}\n",
    "    ]\n",
    "    # Get predicted bias classification from model\n",
    "    result = pipe(prompt, max_new_tokens=10, do_sample=False)\n",
    "    generated_text = result[0]['generated_text']\n",
    "    predicted = generated_text[-1][\"content\"].strip().split(\"\\n\")[0]\n",
    "\n",
    "    for cls in bias_classes:\n",
    "        if cls.lower() in predicted.lower():\n",
    "            return cls\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Mistral to predict bias of every policy\n",
    "for i in tqdm(range(len(df))):\n",
    "    prediction = classify_bias(df.loc[i, \"policy_perturbed\"])\n",
    "    df.loc[i, \"predicted_bias_perturbed\"] = prediction\n",
    "    df.to_csv(\"mistral_few_shot_perturbed.csv\", index = False)\n",
    "\n",
    "# Calculate the number of correct bias predictions\n",
    "df['correct_perturbed'] = df['bias_type_merged'].str.strip().str.lower() == df['predicted_bias_perturbed'].str.strip().str.lower()\n",
    "\n",
    "df.to_csv(\"mistral_few_shot_perturbed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation results for Mistral bias predictions\n",
    "df = pd.read_csv(\"mistral_few_shot_perturbed.csv\")\n",
    "accuracy = df['correct_perturbed'].mean()\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "labels = df[\"bias_type_merged\"].tolist()\n",
    "predictions = df[\"predicted_bias_perturbed\"].tolist()\n",
    "\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
